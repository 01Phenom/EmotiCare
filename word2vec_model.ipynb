{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28UD_FW-XhQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06b54e9-f1db-4ce3-d804-04555be6be99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from time import time\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "rJCTIfQuC9ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "    print(\"Directory changed\")\n",
        "except OSError:\n",
        "    print(\"Error: Can't change the Current Working Directory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyYnybuJDBo6",
        "outputId": "a3573315-5069-469f-f66f-bb7787eebddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory changed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "#SEED = 4222"
      ],
      "metadata": {
        "id": "tPHDl1dzDjRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suicide_detection_df = pd.read_csv('Data/suicide_detection_final_cleaned.csv', header=0)\n",
        "suicide_detection_df.reset_index(drop=True, inplace=True)\n",
        "suicide_detection_df.replace({\"class\": {\"suicide\": 1, \"non-suicide\": 0}}, inplace=True)\n",
        "suicide_detection_df.drop(columns=['text'], inplace=True)\n",
        "suicide_detection_df = suicide_detection_df.rename(columns={\"cleaned_text\": \"text\"})"
      ],
      "metadata": {
        "id": "Oa9Rre3LDkhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, test_text, train_labels, test_labels = train_test_split(suicide_detection_df['text'], suicide_detection_df['class'],\n",
        "\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    stratify=suicide_detection_df['class'])\n"
      ],
      "metadata": {
        "id": "WLjTJ9lzEDUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define vocab\n",
        "vocab = Counter()\n",
        "# tokenise each sentence\n",
        "tokens_list = [(s.split()) for s in train_text]\n",
        "# add each sentence to vocab\n",
        "for i in tokens_list:\n",
        "  vocab.update(i)\n",
        "# removing words with a low occurance\n",
        "min_occurance = 2\n",
        "tokens = [k for k,c in vocab.items() if c >= min_occurance]"
      ],
      "metadata": {
        "id": "bykHrWrfF2TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save list to file\n",
        "def save_list(lines, filename):\n",
        "\t# convert lines to a single blob of text\n",
        "\tdata = '\\n'.join(lines)\n",
        "\t# open file\n",
        "\tfile = open(filename, 'w')\n",
        "\t# write text\n",
        "\tfile.write(data)\n",
        "\t# close file\n",
        "\tfile.close()\n",
        "\n",
        "# save tokens to a vocabulary file\n",
        "save_list(vocab, 'Data/vocab.txt')"
      ],
      "metadata": {
        "id": "qCZ4fu0vF9Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load the vocabulary\n",
        "vocab_filename = 'Data/vocab.txt'\n",
        "vocab = load_doc(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)"
      ],
      "metadata": {
        "id": "nNLpfj3JF_PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean each line\n",
        "def clean_line(line, vocab):\n",
        "  tokens = line.split()\n",
        "  # filter out tokens not in vocab\n",
        "  tokens_clean = [w for w in tokens if w in vocab]\n",
        "  return [tokens_clean]\n",
        "\n",
        "# clean entire dataset\n",
        "def process_lines(data, vocab):\n",
        "  lines = list()\n",
        "  for i in data:\n",
        "    line = clean_line(i, vocab)\n",
        "    # add lines to list\n",
        "    lines += line\n",
        "  return lines"
      ],
      "metadata": {
        "id": "wn242daMHTw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clean = process_lines(train_text, vocab)\n",
        "test_clean = process_lines(test_text, vocab)"
      ],
      "metadata": {
        "id": "njXdKDRYHjIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the parameters of the model\n",
        "model = Word2Vec(vector_size=300, window=10, min_count=1, epochs=EPOCHS)\n",
        "\n",
        "\n",
        "# it builds the vocabulary from a sequence of sentences and thus initialized the model.\n",
        "t = time()\n",
        "model.build_vocab(train_clean, progress_per=1000)\n",
        "# training the model\n",
        "t = time()\n",
        "model.train(train_clean, total_examples=model.corpus_count, epochs=EPOCHS, report_delay=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSZP_5gpH9FT",
        "outputId": "57de3c38-2021-4960-9f3f-11f0a3dcdf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1022116, 1253510)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Data/embedding_word2vec.txt'\n",
        "model.wv.save_word2vec_format(filename, binary=False)"
      ],
      "metadata": {
        "id": "CEqG52-YI1hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('suicide')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyh4mClSJWgn",
        "outputId": "44ff0bd2-1ea6-4614-c0f9-d629df87ae03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('commit', 0.9702114462852478),\n",
              " ('attempt', 0.9699046611785889),\n",
              " ('thought', 0.9639476537704468),\n",
              " ('plan', 0.9514110684394836),\n",
              " ('tendency', 0.9481505751609802),\n",
              " ('suicidal', 0.9464195966720581),\n",
              " ('depression', 0.9458267092704773),\n",
              " ('relief', 0.945617139339447),\n",
              " ('think', 0.9445353150367737),\n",
              " ('hospital', 0.9420954585075378)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u2J_8G8rJWDA"
      }
    }
  ]
}